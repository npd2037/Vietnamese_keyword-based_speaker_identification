{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b258be0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-20T10:24:07.525013Z",
     "iopub.status.busy": "2025-10-20T10:24:07.523905Z",
     "iopub.status.idle": "2025-10-20T10:24:08.283313Z",
     "shell.execute_reply": "2025-10-20T10:24:08.282283Z"
    },
    "papermill": {
     "duration": 0.767133,
     "end_time": "2025-10-20T10:24:08.284786",
     "exception": false,
     "start_time": "2025-10-20T10:24:07.517653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Res2Net/Res2Net-PretrainedModels.git\n",
    "\n",
    "import sys\n",
    "sys.path.append('/kaggle/working/Res2Net-PretrainedModels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ecb39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:24:08.294801Z",
     "iopub.status.busy": "2025-10-20T10:24:08.294311Z",
     "iopub.status.idle": "2025-10-20T10:24:08.418385Z",
     "shell.execute_reply": "2025-10-20T10:24:08.417334Z"
    },
    "papermill": {
     "duration": 0.13082,
     "end_time": "2025-10-20T10:24:08.420214",
     "exception": false,
     "start_time": "2025-10-20T10:24:08.289394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!grep -E \"def |class \" /kaggle/working/Res2Net-PretrainedModels/res2net_v1b.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc16c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from res2net_v1b import res2net50_v1b_26w_4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d9161",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:24:14.985610Z",
     "iopub.status.busy": "2025-10-20T10:24:14.985218Z",
     "iopub.status.idle": "2025-10-20T10:24:14.990453Z",
     "shell.execute_reply": "2025-10-20T10:24:14.989642Z"
    },
    "papermill": {
     "duration": 0.011201,
     "end_time": "2025-10-20T10:24:14.991604",
     "exception": false,
     "start_time": "2025-10-20T10:24:14.980403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------------- Config / Hyperparams -------------------------\n",
    "DEFAULT_SR = 16000        \n",
    "AUDIO_DURATION = 2.5    \n",
    "N_MELS = 128             \n",
    "N_FFT = 1024                \n",
    "HOP_LENGTH = 256       \n",
    "\n",
    "EMBEDDING_SIZE = 256       \n",
    "\n",
    "EPOCHS = 20               \n",
    "BATCH_SIZE = 64            \n",
    "LR = 1e-3                  \n",
    "\n",
    "SPLIT_RATIO = (0.8, 0.2)     \n",
    "MIN_UTTS_PER_SPK = 2  \n",
    "\n",
    "TRAIN_ROOT = \"/kaggle/input/voxvn-api491/train_small_wav\"\n",
    "TEST_ROOT = \"/kaggle/input/voxvietnam\"\n",
    "AUDIO_DIR_TEST = os.path.join(TEST_ROOT, \"wav\", \"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15c83b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:24:15.000564Z",
     "iopub.status.busy": "2025-10-20T10:24:15.000022Z",
     "iopub.status.idle": "2025-10-20T10:24:15.005759Z",
     "shell.execute_reply": "2025-10-20T10:24:15.004932Z"
    },
    "papermill": {
     "duration": 0.011482,
     "end_time": "2025-10-20T10:24:15.007019",
     "exception": false,
     "start_time": "2025-10-20T10:24:14.995537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_audio(path: str, sr: int = DEFAULT_SR, duration: float = AUDIO_DURATION, random_crop: bool = False):\n",
    "    wav, orig_sr = sf.read(path)   \n",
    "    if wav.ndim > 1:\n",
    "        wav = np.mean(wav, axis=1)\n",
    "    \n",
    "    if orig_sr != sr:\n",
    "        wav = librosa.resample(wav.astype('float32'), orig_sr, sr)\n",
    "    \n",
    "    target_len = int(sr * duration)\n",
    "    \n",
    "    if len(wav) >= target_len:\n",
    "        if random_crop:\n",
    "            start = np.random.randint(0, len(wav) - target_len + 1)\n",
    "        else:\n",
    "            start = 0\n",
    "        wav = wav[start:start + target_len]\n",
    "    else:\n",
    "        pad_width = target_len - len(wav)\n",
    "        wav = np.pad(wav, (0, pad_width), mode='constant')\n",
    "    \n",
    "    return wav.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c123f6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:24:15.015699Z",
     "iopub.status.busy": "2025-10-20T10:24:15.015478Z",
     "iopub.status.idle": "2025-10-20T10:24:15.020699Z",
     "shell.execute_reply": "2025-10-20T10:24:15.020089Z"
    },
    "papermill": {
     "duration": 0.010817,
     "end_time": "2025-10-20T10:24:15.021909",
     "exception": false,
     "start_time": "2025-10-20T10:24:15.011092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def waveform_to_features(\n",
    "    wav: torch.Tensor, \n",
    "    sr=DEFAULT_SR,\n",
    "    n_fft=N_FFT, \n",
    "    hop_length=HOP_LENGTH,\n",
    "    n_mels=N_MELS, \n",
    "    normalize=True\n",
    "):\n",
    "\n",
    "    if isinstance(wav, np.ndarray):\n",
    "        wav = torch.tensor(wav, dtype=torch.float32)\n",
    "\n",
    "    mel_spec = T.MelSpectrogram(\n",
    "        sample_rate=sr,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "        power=2.0\n",
    "    )(wav.unsqueeze(0))\n",
    "\n",
    "    log_mel = T.AmplitudeToDB()(mel_spec).squeeze(0) \n",
    "    if normalize:\n",
    "        log_mel = (log_mel - log_mel.mean()) / (log_mel.std() + 1e-6)\n",
    "    features = log_mel.unsqueeze(0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af4630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:24:15.030849Z",
     "iopub.status.busy": "2025-10-20T10:24:15.030401Z",
     "iopub.status.idle": "2025-10-20T10:24:23.031795Z",
     "shell.execute_reply": "2025-10-20T10:24:23.031184Z"
    },
    "papermill": {
     "duration": 8.007197,
     "end_time": "2025-10-20T10:24:23.033291",
     "exception": false,
     "start_time": "2025-10-20T10:24:15.026094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scan_dataset(root, min_utts_per_spk=MIN_UTTS_PER_SPK):\n",
    "    all_files = glob.glob(os.path.join(root, \"*\", \"*.wav\"))\n",
    "    speakers = sorted(list({os.path.basename(os.path.dirname(f)) for f in all_files}))\n",
    "    spk2idx = {spk: i for i, spk in enumerate(speakers)}\n",
    "    spk2files = defaultdict(list)\n",
    "    for f in all_files:\n",
    "        spk2files[spk2idx[os.path.basename(os.path.dirname(f))]].append(f)\n",
    "    # dùng min_utts_per_spk từ config\n",
    "    spk2files = {k: v for k, v in spk2files.items() if len(v) >= min_utts_per_spk}\n",
    "    return spk2files\n",
    "\n",
    "\n",
    "spk2files = scan_dataset(TRAIN_ROOT)\n",
    "valid_spks = list(spk2files.keys())\n",
    "random.shuffle(valid_spks)\n",
    "split_idx = int(len(valid_spks)*0.8)\n",
    "\n",
    "spk2files_train = {k: spk2files[k] for k in valid_spks[:split_idx]}\n",
    "spk2files_val = {k: spk2files[k] for k in valid_spks[split_idx:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5099cc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:24:23.057468Z",
     "iopub.status.busy": "2025-10-20T10:24:23.057250Z",
     "iopub.status.idle": "2025-10-20T10:24:23.073851Z",
     "shell.execute_reply": "2025-10-20T10:24:23.072997Z"
    },
    "papermill": {
     "duration": 0.022266,
     "end_time": "2025-10-20T10:24:23.075039",
     "exception": false,
     "start_time": "2025-10-20T10:24:23.052773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_file = spk2files_train[list(spk2files_train.keys())[0]][0]\n",
    "wav = read_audio(sample_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f5c242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:24:23.083976Z",
     "iopub.status.busy": "2025-10-20T10:24:23.083773Z",
     "iopub.status.idle": "2025-10-20T10:24:23.251098Z",
     "shell.execute_reply": "2025-10-20T10:24:23.249991Z"
    },
    "papermill": {
     "duration": 0.173422,
     "end_time": "2025-10-20T10:24:23.252536",
     "exception": false,
     "start_time": "2025-10-20T10:24:23.079114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = waveform_to_features(wav)\n",
    "print(\"Feature shape:\", features.shape)\n",
    "print(\"Mean / Std:\", features.mean().item(), features.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0120c6bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:24:23.263875Z",
     "iopub.status.busy": "2025-10-20T10:24:23.263185Z",
     "iopub.status.idle": "2025-10-20T10:24:23.273656Z",
     "shell.execute_reply": "2025-10-20T10:24:23.272938Z"
    },
    "papermill": {
     "duration": 0.017342,
     "end_time": "2025-10-20T10:24:23.274829",
     "exception": false,
     "start_time": "2025-10-20T10:24:23.257487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TripletSpeakerDataset(Dataset):\n",
    "    def __init__(self, spk2files, sr=DEFAULT_SR, duration=AUDIO_DURATION,\n",
    "                 n_mels=N_MELS,\n",
    "                 augment=True, transform=None, random_crop=True, debug=False):\n",
    "        self.spk2files = spk2files\n",
    "        self.speakers = list(spk2files.keys())\n",
    "        self.sr = sr\n",
    "        self.duration = duration\n",
    "        self.n_mels = n_mels\n",
    "        self.augment = augment\n",
    "        self.transform = transform\n",
    "        self.random_crop = random_crop\n",
    "        self.debug = debug\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(v) for v in self.spk2files.values())\n",
    "\n",
    "    def _load_feature(self, path):\n",
    "        wav = read_audio(path, sr=self.sr, duration=self.duration, random_crop=self.random_crop)\n",
    "\n",
    "        if self.augment:\n",
    "            wav = augment_waveform(wav, self.sr)\n",
    "\n",
    "        features = waveform_to_features(\n",
    "            wav, sr=self.sr,\n",
    "            n_mels=self.n_mels,\n",
    "            normalize=True\n",
    "        )\n",
    "\n",
    "        features = features.repeat(3, 1, 1) \n",
    "\n",
    "        features = F.interpolate(\n",
    "            features.unsqueeze(0),\n",
    "            size=(224, 224),\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        ).squeeze(0) \n",
    "\n",
    "        if self.augment and random.random() < 0.3:\n",
    "            features = spec_augment(features)\n",
    "\n",
    "        if self.transform:\n",
    "            features = self.transform(features)\n",
    "\n",
    "        return features\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        spk = random.choice(self.speakers)\n",
    "        pos_files = self.spk2files[spk]\n",
    "\n",
    "        if len(pos_files) < 2:\n",
    "            return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "\n",
    "        anchor_path, pos_path = random.sample(pos_files, 2)\n",
    "\n",
    "        neg_spk = random.choice([s for s in self.speakers if s != spk])\n",
    "        neg_path = random.choice(self.spk2files[neg_spk])\n",
    "\n",
    "        anchor = self._load_feature(anchor_path)\n",
    "        positive = self._load_feature(pos_path)\n",
    "        negative = self._load_feature(neg_path)\n",
    "\n",
    "        return anchor, positive, negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9987254",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:24:23.284629Z",
     "iopub.status.busy": "2025-10-20T10:24:23.284123Z",
     "iopub.status.idle": "2025-10-20T10:24:23.404318Z",
     "shell.execute_reply": "2025-10-20T10:24:23.403284Z"
    },
    "papermill": {
     "duration": 0.126485,
     "end_time": "2025-10-20T10:24:23.405710",
     "exception": false,
     "start_time": "2025-10-20T10:24:23.279225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TripletSpeakerDataset(spk2files_train, random_crop=True, augment=False)\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True)\n",
    "for a, p, n in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e45a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:24:23.417905Z",
     "iopub.status.busy": "2025-10-20T10:24:23.417608Z",
     "iopub.status.idle": "2025-10-20T10:24:23.424502Z",
     "shell.execute_reply": "2025-10-20T10:24:23.423805Z"
    },
    "papermill": {
     "duration": 0.014342,
     "end_time": "2025-10-20T10:24:23.425723",
     "exception": false,
     "start_time": "2025-10-20T10:24:23.411381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def augment_waveform(wav, sr):\n",
    "    if random.random() < 0.5:\n",
    "        aug_type = random.choice([\"noise\", \"gain\"])\n",
    "        wav_tensor = torch.tensor(wav, dtype=torch.float32)\n",
    "\n",
    "        if aug_type == \"noise\":\n",
    "            noise = torch.randn_like(wav_tensor) * random.uniform(0.001, 0.01)\n",
    "            wav_tensor += noise\n",
    "        elif aug_type == \"gain\":\n",
    "            gain = random.uniform(-6, 6)\n",
    "            wav_tensor *= 10 ** (gain / 20)\n",
    "\n",
    "        wav_tensor = torch.clamp(wav_tensor, -1.0, 1.0)\n",
    "        wav = wav_tensor.numpy()\n",
    "\n",
    "    return wav\n",
    "\n",
    "def spec_augment(mel):\n",
    "    mel = mel.clone()\n",
    "    freq_mask = random.randint(1, max(1, mel.size(0)//8))\n",
    "    time_mask = random.randint(1, max(1, mel.size(1)//8))\n",
    "    f0 = random.randint(0, mel.size(0)-freq_mask)\n",
    "    t0 = random.randint(0, mel.size(1)-time_mask)\n",
    "    mel[f0:f0+freq_mask, :] = 0\n",
    "    mel[:, t0:t0+time_mask] = 0\n",
    "    return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b610d9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:24:23.437474Z",
     "iopub.status.busy": "2025-10-20T10:24:23.436796Z",
     "iopub.status.idle": "2025-10-20T10:24:32.709621Z",
     "shell.execute_reply": "2025-10-20T10:24:32.708936Z"
    },
    "papermill": {
     "duration": 9.279404,
     "end_time": "2025-10-20T10:24:32.711069",
     "exception": false,
     "start_time": "2025-10-20T10:24:23.431665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, 1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        scale = self.avg_pool(x)\n",
    "        scale = self.fc1(scale)\n",
    "        scale = self.relu(scale)\n",
    "        scale = self.fc2(scale)\n",
    "        scale = self.sigmoid(scale)\n",
    "        return x * scale\n",
    "\n",
    "class SERes2NetEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_size=EMBEDDING_SIZE, pretrained=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = res2net50_v1b_26w_4s(pretrained=pretrained)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        self.se_block = SEModule(2048, reduction=16)\n",
    "\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(2048, embedding_size),\n",
    "            nn.BatchNorm1d(embedding_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_emb=False, normalize_emb=False):\n",
    "        if x.size(1) == 1:\n",
    "            x = x.repeat(1, 3, 1, 1)\n",
    "\n",
    "        feat = self.backbone.forward(x)\n",
    "        feat = feat.view(feat.size(0), 2048, 1, 1)\n",
    "        feat = self.se_block(feat)\n",
    "        feat = feat.view(feat.size(0), -1)\n",
    "\n",
    "        emb = self.embedding(feat)\n",
    "        if normalize_emb:\n",
    "            emb = F.normalize(emb, p=2, dim=1)\n",
    "\n",
    "        return emb\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SERes2NetEmbedding(embedding_size=256, pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1af3d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:24:32.727988Z",
     "iopub.status.busy": "2025-10-20T10:24:32.727048Z",
     "iopub.status.idle": "2025-10-20T10:24:32.735278Z",
     "shell.execute_reply": "2025-10-20T10:24:32.734633Z"
    },
    "papermill": {
     "duration": 0.017307,
     "end_time": "2025-10-20T10:24:32.736408",
     "exception": false,
     "start_time": "2025-10-20T10:24:32.719101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_voxvietnam_pairs(root):\n",
    "    csv_path = os.path.join(root, \"test_list_gt.csv\")\n",
    "    txt_path = os.path.join(root, \"test_list.txt\")\n",
    "    path = csv_path if os.path.exists(csv_path) else txt_path\n",
    "    assert os.path.exists(path), f\"Không tìm thấy test list: {csv_path} | {txt_path}\"\n",
    "\n",
    "    pairs = []\n",
    "    with open(path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        for raw in f:\n",
    "            line = raw.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            line = line.replace('\"', '').replace(',', ' ').replace('\\t', ' ')\n",
    "            parts = [p for p in line.split() if p.strip()]\n",
    "            if len(parts) != 3:\n",
    "                parts_col = [line]\n",
    "                while len(parts_col) < 3:\n",
    "                    nxt = f.readline()\n",
    "                    if not nxt:\n",
    "                        break\n",
    "                    nxt = nxt.strip().replace('\"','').replace(',', ' ').replace('\\t',' ')\n",
    "                    if nxt:\n",
    "                        parts_col.append(nxt)\n",
    "                parts_join = [p for p in \" \".join(parts_col).split() if p.strip()]\n",
    "                if len(parts_join) != 3:\n",
    "                    print(f\"Bỏ qua dòng lỗi: {raw.strip()}\")\n",
    "                    continue\n",
    "                parts = parts_join\n",
    "\n",
    "            label_str, f1, f2 = parts\n",
    "            try:\n",
    "                label = int(label_str)\n",
    "                pairs.append((f1.strip(), f2.strip(), label))\n",
    "            except ValueError:\n",
    "                print(f\"Bỏ qua dòng lỗi (label không hợp lệ): {raw.strip()}\")\n",
    "                continue\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b196641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:24:32.752382Z",
     "iopub.status.busy": "2025-10-20T10:24:32.751664Z",
     "iopub.status.idle": "2025-10-20T10:24:32.761794Z",
     "shell.execute_reply": "2025-10-20T10:24:32.760894Z"
    },
    "papermill": {
     "duration": 0.019218,
     "end_time": "2025-10-20T10:24:32.763035",
     "exception": false,
     "start_time": "2025-10-20T10:24:32.743817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_eer_test(model, pairs, audio_dir=AUDIO_DIR_TEST, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.eval()\n",
    "    embeddings_cache = {}\n",
    "\n",
    "    def get_embedding(path):\n",
    "        if path in embeddings_cache:\n",
    "            return embeddings_cache[path]\n",
    "\n",
    "        full_path = os.path.join(audio_dir, path)\n",
    "        wav = read_audio(full_path)  # đọc waveform\n",
    "        feat = waveform_to_features(wav, normalize=True) \n",
    "        if feat.size(0) == 1:\n",
    "            feat = feat.repeat(3, 1, 1)\n",
    "        feat = F.interpolate(feat.unsqueeze(0), size=(224, 224), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "        feat = feat.unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            emb = model(feat, return_emb=True, normalize_emb=True)\n",
    "        emb = emb.cpu().numpy().flatten()\n",
    "        embeddings_cache[path] = emb\n",
    "        return emb\n",
    "\n",
    "    scores, targets = [], []\n",
    "\n",
    "    for f1, f2, label in pairs:\n",
    "        try:\n",
    "            emb1 = get_embedding(f1)\n",
    "            emb2 = get_embedding(f2)\n",
    "            sim = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2) + 1e-6)\n",
    "            scores.append(sim)\n",
    "            targets.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi xử lý {f1}, {f2}: {e}\")\n",
    "            continue\n",
    "\n",
    "    scores = np.array(scores)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(targets, scores)\n",
    "    fnr = 1 - tpr\n",
    "    eer_idx = np.nanargmin(np.abs(fnr - fpr))\n",
    "    eer = (fpr[eer_idx] + fnr[eer_idx]) / 2\n",
    "    thr = thresholds[eer_idx]\n",
    "\n",
    "    print(f\"EER: {eer:.4f}, Threshold: {thr:.4f}\")\n",
    "    return eer, thr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fbb877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:24:32.778638Z",
     "iopub.status.busy": "2025-10-20T10:24:32.778384Z",
     "iopub.status.idle": "2025-10-20T10:24:32.907447Z",
     "shell.execute_reply": "2025-10-20T10:24:32.906549Z"
    },
    "papermill": {
     "duration": 0.138474,
     "end_time": "2025-10-20T10:24:32.908852",
     "exception": false,
     "start_time": "2025-10-20T10:24:32.770378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_triplet_with_eer(model, spk2files_tr, spk2files_va,\n",
    "                            pairs=None, test_root=TEST_ROOT,\n",
    "                            epochs=EPOCHS, batch_size=BATCH_SIZE, lr=LR,\n",
    "                            weight_decay=1e-4, margin=0.3,\n",
    "                            device=None):\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    train_ds = TripletSpeakerDataset(spk2files_tr, random_crop=True, augment=True)\n",
    "    val_ds   = TripletSpeakerDataset(spk2files_va, random_crop=False, augment=False)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n",
    "                            num_workers=2, pin_memory=True)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=epochs, eta_min=1e-6\n",
    "    )\n",
    "\n",
    "    criterion = nn.TripletMarginLoss(margin=margin, p=2)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    if pairs is None:\n",
    "        pairs = load_voxvietnam_pairs(test_root)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "\n",
    "        for anchor, positive, negative in train_loader:\n",
    "            anchor, positive, negative = (\n",
    "                anchor.to(device, non_blocking=True),\n",
    "                positive.to(device, non_blocking=True),\n",
    "                negative.to(device, non_blocking=True)\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                emb_a = model(anchor, return_emb=True, normalize_emb=True)\n",
    "                emb_p = model(positive, return_emb=True, normalize_emb=True)\n",
    "                emb_n = model(negative, return_emb=True, normalize_emb=True)\n",
    "\n",
    "                loss = criterion(emb_a, emb_p, emb_n)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        train_loss = total_loss / max(1, num_batches)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_batches = 0\n",
    "        with torch.no_grad():\n",
    "            for anchor, positive, negative in val_loader:\n",
    "                anchor, positive, negative = (\n",
    "                    anchor.to(device, non_blocking=True),\n",
    "                    positive.to(device, non_blocking=True),\n",
    "                    negative.to(device, non_blocking=True)\n",
    "                )\n",
    "                with autocast():\n",
    "                    emb_a = model(anchor, return_emb=True, normalize_emb=True)\n",
    "                    emb_p = model(positive, return_emb=True, normalize_emb=True)\n",
    "                    emb_n = model(negative, return_emb=True, normalize_emb=True)\n",
    "                    loss = criterion(emb_a, emb_p, emb_n)\n",
    "                val_loss += loss.item()\n",
    "                val_batches += 1\n",
    "\n",
    "        val_loss /= max(1, val_batches)\n",
    "        scheduler.step()\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | LR: {current_lr:.6f}\")\n",
    "\n",
    "        try:\n",
    "            eer, thr = compute_eer_test(model, pairs, audio_dir=AUDIO_DIR_TEST, device=device)\n",
    "            print(f\"Epoch {epoch}/{epochs} | EER-Test: {eer:.4f} | Threshold: {thr:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Skipped EER-Test computation due to error: {e}\")\n",
    "\n",
    "        save_path = f\"triplet_se_res2net_epoch{epoch}.pth\"\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"scaler_state\": scaler.state_dict(),\n",
    "        }, save_path)\n",
    "        print(f\"Saved checkpoint: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17927f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T10:24:32.925084Z",
     "iopub.status.busy": "2025-10-20T10:24:32.924399Z",
     "iopub.status.idle": "2025-10-20T19:12:45.955827Z",
     "shell.execute_reply": "2025-10-20T19:12:45.954757Z"
    },
    "papermill": {
     "duration": 31693.041172,
     "end_time": "2025-10-20T19:12:45.957475",
     "exception": false,
     "start_time": "2025-10-20T10:24:32.916303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SERes2NetEmbedding(embedding_size=EMBEDDING_SIZE, pretrained=False).to(device)\n",
    "\n",
    "pairs = load_voxvietnam_pairs(TEST_ROOT)\n",
    "pairs = [(f1.replace(\"wav/\", \"\"), f2.replace(\"wav/\", \"\"), label) for f1, f2, label in pairs]\n",
    "\n",
    "train_triplet_with_eer(\n",
    "    model,\n",
    "    spk2files_tr=spk2files_train,\n",
    "    spk2files_va=spk2files_val,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LR,\n",
    "    weight_decay=1e-4,\n",
    "    margin=0.3,\n",
    "    device=device,\n",
    "    pairs=pairs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7251391,
     "sourceId": 11565412,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8345362,
     "sourceId": 13169831,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31726.095134,
   "end_time": "2025-10-20T19:12:49.539521",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-20T10:24:03.444387",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
