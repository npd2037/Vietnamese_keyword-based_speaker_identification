{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1072103",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-14T11:42:14.544609Z",
     "iopub.status.busy": "2025-11-14T11:42:14.544356Z"
    },
    "papermill": {
     "duration": 43200.004887,
     "end_time": "2025-11-14T23:42:14.545509",
     "exception": false,
     "start_time": "2025-11-14T11:42:14.540622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os, glob, random, math, csv\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch, torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE, \"| Torch:\", torch.__version__, \"| Torchaudio:\", torchaudio.__version__)\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if DEVICE == \"cuda\": torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "AMP_DTYPE = torch.bfloat16 if (DEVICE==\"cuda\" and torch.cuda.is_bf16_supported()) else torch.float16\n",
    "USE_SCALER = (AMP_DTYPE == torch.float16)\n",
    "\n",
    "TRAIN_ROOT = \"/kaggle/input/voxvn-api491/train_small_wav\"   \n",
    "TEST_ROOT  = \"/kaggle/input/voxvietnam\"                     \n",
    "assert os.path.exists(TRAIN_ROOT), f\"Không thấy train folder: {TRAIN_ROOT}\"\n",
    "assert os.path.exists(TEST_ROOT),  f\"Không thấy test folder: {TEST_ROOT}\"\n",
    "\n",
    "\n",
    "def scan_dataset(root):\n",
    "    all_files = glob.glob(os.path.join(root, \"*\", \"*.wav\"))\n",
    "    speakers = sorted(list({os.path.basename(os.path.dirname(f)) for f in all_files}))\n",
    "    spk2idx = {spk: i for i, spk in enumerate(speakers)}\n",
    "    spk2files = defaultdict(list)\n",
    "    for f in all_files:\n",
    "        spk2files[spk2idx[os.path.basename(os.path.dirname(f))]].append(f)\n",
    "   \n",
    "    spk2files = {k: v for k, v in spk2files.items() if len(v) >= 2}\n",
    "    return spk2files\n",
    "\n",
    "spk2files_train = scan_dataset(TRAIN_ROOT)\n",
    "print(f\" Train dataset: {len(spk2files_train)} speakers\")\n",
    "\n",
    "valid_spks = sorted(list(spk2files_train.keys()))\n",
    "spk_map = {spk: i for i, spk in enumerate(valid_spks)}\n",
    "train_set = [(f, spk_map[spk]) for spk, files in spk2files_train.items() for f in files]\n",
    "num_classes = len(spk_map)\n",
    "print(f\"Train: {len(train_set)} | Classes: {num_classes} | Label range check → \"\n",
    "      f\"{min(l for _,l in train_set)} … {max(l for _,l in train_set)}\")\n",
    "\n",
    "\n",
    "def load_voxvietnam_pairs(root):\n",
    "    csv_path = os.path.join(root, \"test_list_gt.csv\")\n",
    "    txt_path = os.path.join(root, \"test_list.txt\")\n",
    "    path = csv_path if os.path.exists(csv_path) else txt_path\n",
    "    assert os.path.exists(path), f\"Không tìm thấy test list: {csv_path} | {txt_path}\"\n",
    "\n",
    "    pairs = []\n",
    "    with open(path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        for raw in f:\n",
    "            line = raw.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            line = line.replace('\"', '').replace(',', ' ').replace('\\t', ' ')\n",
    "            parts = [p for p in line.split() if p.strip()]\n",
    "            if len(parts) != 3:\n",
    "                parts_col = [line]\n",
    "                while len(parts_col) < 3:\n",
    "                    nxt = f.readline()\n",
    "                    if not nxt:\n",
    "                        break\n",
    "                    nxt = nxt.strip().replace('\"','').replace(',', ' ').replace('\\t',' ')\n",
    "                    if nxt:\n",
    "                        parts_col.append(nxt)\n",
    "                parts_join = [p for p in \" \".join(parts_col).split() if p.strip()]\n",
    "                if len(parts_join) != 3:\n",
    "                    print(f\"[WARN] Bỏ qua dòng lỗi: {raw.strip()}\")\n",
    "                    continue\n",
    "                parts = parts_join\n",
    "            label_str, f1, f2 = parts\n",
    "            try:\n",
    "                label = int(label_str)\n",
    "                pairs.append((f1.strip(), f2.strip(), label))\n",
    "            except ValueError:\n",
    "                print(f\"[WARN] Bỏ qua dòng lỗi (label không hợp lệ): {raw.strip()}\")\n",
    "                continue\n",
    "\n",
    "    print(f\" Loaded {len(pairs)} pairs from {os.path.basename(path)}\")\n",
    "    if pairs:\n",
    "        print(\" Ví dụ:\", pairs[0])\n",
    "    return pairs\n",
    "\n",
    "pairs = load_voxvietnam_pairs(TEST_ROOT)\n",
    "\n",
    "\n",
    "class VoiceDataset(Dataset):\n",
    "    def __init__(self, samples, augment=False, max_len=3.0, sr=16000, n_mels=80):\n",
    "        self.samples = samples\n",
    "        self.augment = augment\n",
    "        self.sr = sr\n",
    "        self.max_len = max_len\n",
    "        self.mel_tf = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=sr, n_fft=400, hop_length=160, n_mels=n_mels\n",
    "        )\n",
    "        \n",
    "        self.freq_mask = torchaudio.transforms.FrequencyMasking(freq_mask_param=15)\n",
    "        self.time_mask = torchaudio.transforms.TimeMasking(time_mask_param=35)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def _augment_wave(self, wav):\n",
    "        T = wav.size(1)\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            gain = random.uniform(0.8, 1.2)\n",
    "            wav = wav * gain\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            snr_db = random.uniform(5, 20)\n",
    "            sig_power = wav.pow(2).mean().clamp(min=1e-9)\n",
    "            noise_power = sig_power / (10 ** (snr_db / 10))\n",
    "            noise = torch.randn_like(wav)\n",
    "            noise = noise * (noise_power.sqrt() / noise.pow(2).mean().clamp(min=1e-9).sqrt())\n",
    "            wav = wav + noise\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            max_shift = int(0.08 * self.sr)\n",
    "            shift = random.randint(-max_shift, max_shift)\n",
    "            if shift > 0:\n",
    "                wav = torch.cat([torch.zeros(1, shift), wav[:, :-shift]], dim=1)\n",
    "            elif shift < 0:\n",
    "                s = -shift\n",
    "                wav = torch.cat([wav[:, s:], torch.zeros(1, s)], dim=1)\n",
    "\n",
    "        if random.random() < 0.4:\n",
    "            if random.random() < 0.5:\n",
    "                cutoff = random.uniform(200.0, 4000.0)\n",
    "                wav = torchaudio.functional.highpass_biquad(wav, self.sr, cutoff)\n",
    "            else:\n",
    "                cutoff = random.uniform(2000.0, 6000.0)\n",
    "                wav = torchaudio.functional.lowpass_biquad(wav, self.sr, cutoff)\n",
    "\n",
    "        return wav\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        try:\n",
    "            wav, sr = torchaudio.load(path)\n",
    "            if wav.shape[0] > 1:\n",
    "                wav = torch.mean(wav, dim=0, keepdim=True)\n",
    "            if sr != self.sr:\n",
    "                wav = torchaudio.functional.resample(wav, sr, self.sr)\n",
    "\n",
    "            L = int(self.max_len * self.sr)\n",
    "            if wav.size(1) > L:\n",
    "                st = random.randint(0, wav.size(1) - L)\n",
    "                wav = wav[:, st:st + L]\n",
    "            else:\n",
    "                wav = F.pad(wav, (0, L - wav.size(1)))\n",
    "\n",
    "            if self.augment:\n",
    "                wav = self._augment_wave(wav)\n",
    "\n",
    "            mel = torch.log(self.mel_tf(wav) + 1e-6).squeeze(0) \n",
    "\n",
    "            if self.augment:\n",
    "                mel = self.freq_mask(mel)\n",
    "                mel = self.time_mask(mel)\n",
    "\n",
    "            return mel, label\n",
    "        except Exception:\n",
    "            return self.__getitem__((idx + 1) % len(self.samples))\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, r=8):\n",
    "        super().__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Conv1d(channels, channels // r, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(channels // r, channels, kernel_size=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = self.se(x)          \n",
    "        return x * w           \n",
    "\n",
    "class ConvModule(nn.Module):\n",
    "    def __init__(self, dim, k=15):\n",
    "        super().__init__()\n",
    "        self.ln = nn.LayerNorm(dim)\n",
    "        self.pw1 = nn.Conv1d(dim, 2 * dim, 1)\n",
    "        self.dw  = nn.Conv1d(dim, dim, k, padding=k // 2, groups=dim)\n",
    "        self.bn  = nn.BatchNorm1d(dim)\n",
    "        self.act = Swish()\n",
    "        self.pw2 = nn.Conv1d(dim, dim, 1)\n",
    "        self.se  = SEBlock(dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.ln(x).transpose(1, 2)      \n",
    "        y = F.glu(self.pw1(y), dim=1)      \n",
    "        y = self.dw(y)\n",
    "        y = self.bn(y)\n",
    "        y = self.act(y)\n",
    "        y = self.pw2(y)\n",
    "        y = self.se(y)                      \n",
    "        y = y.transpose(1, 2)              \n",
    "        return x + y\n",
    "\n",
    "class FeedForwardModule(nn.Module):\n",
    "    def __init__(self, dim, exp=4, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.ln = nn.LayerNorm(dim)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(dim, exp * dim), Swish(), nn.Dropout(drop),\n",
    "            nn.Linear(exp * dim, dim), nn.Dropout(drop),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + 0.5 * self.ff(self.ln(x))\n",
    "\n",
    "class MHSA(nn.Module):\n",
    "    def __init__(self, dim, h=4, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.ln = nn.LayerNorm(dim)\n",
    "        self.attn = nn.MultiheadAttention(dim, h, dropout=drop, batch_first=True)\n",
    "        self.do = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y, _ = self.attn(self.ln(x), self.ln(x), self.ln(x))\n",
    "        return x + self.do(y)\n",
    "\n",
    "class ConformerBlock(nn.Module):\n",
    "    def __init__(self, dim, h=4, k=15, exp=4, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.ff1 = FeedForwardModule(dim, exp, drop)\n",
    "        self.mhsa = MHSA(dim, h, drop)\n",
    "        self.conv = ConvModule(dim, k)\n",
    "        self.ff2 = FeedForwardModule(dim, exp, drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ff2(self.conv(self.mhsa(self.ff1(x))))\n",
    "\n",
    "class MFAConformer(nn.Module):\n",
    "    def __init__(self, n_mels=80, dim=224, L=6, h=4, k=15, exp=4,\n",
    "                 drop=0.1, emb_dim=192):\n",
    "        super().__init__()\n",
    "\n",
    "        self.proj = nn.Linear(n_mels, dim)\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ConformerBlock(dim, h=h, k=k, exp=exp, drop=drop)\n",
    "            for _ in range(L)\n",
    "        ])\n",
    "\n",
    "        self.ln_mfa = nn.LayerNorm(dim * L)\n",
    "\n",
    "        self.post = nn.Linear(dim * L * 2, emb_dim)\n",
    "        self.bn = nn.BatchNorm1d(emb_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)       \n",
    "        x = self.proj(x)          \n",
    "\n",
    "        feats = []\n",
    "        for b in self.blocks:\n",
    "            x = b(x)\n",
    "            feats.append(x)\n",
    "\n",
    "        H = torch.cat(feats, dim=-1)  \n",
    "        H = self.ln_mfa(H)\n",
    "\n",
    "        mean = H.mean(dim=1)\n",
    "        std = H.std(dim=1).clamp(min=1e-6)\n",
    "        pooled = torch.cat([mean, std], dim=1)\n",
    "\n",
    "        emb = self.bn(self.post(pooled))\n",
    "        emb = torch.nan_to_num(emb)\n",
    "        return F.normalize(emb, p=2, dim=1)\n",
    "\n",
    "\n",
    "class AAMSoftmax(nn.Module):\n",
    "    def __init__(self, emb_dim, num_classes, s=30.0, m=0.2):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.randn(emb_dim, num_classes))\n",
    "        nn.init.xavier_normal_(self.W)\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "\n",
    "    def forward(self, emb, y):\n",
    "\n",
    "        W = F.normalize(self.W, dim=0)          \n",
    "        x = F.normalize(emb, p=2, dim=1)        \n",
    "        logits = x @ W                         \n",
    "\n",
    "        y_onehot = F.one_hot(y, num_classes=W.size(1)).float()\n",
    "        theta = torch.acos(torch.clamp(logits, -1 + 1e-7, 1 - 1e-7))\n",
    "        target_logits = torch.cos(theta + self.m)\n",
    "        logits = logits * (1 - y_onehot) + target_logits * y_onehot\n",
    "        logits = logits * self.s\n",
    "        return logits\n",
    "\n",
    "\n",
    "def compute_eer(scores, labels):\n",
    "    fpr, tpr, _ = roc_curve(labels, scores)\n",
    "    fnr = 1 - tpr\n",
    "    idx = np.nanargmin(np.abs(fnr - fpr))\n",
    "    return float(fpr[idx] * 100)\n",
    "\n",
    "def resolve_test_path(root, rel):\n",
    "    p = os.path.join(root, rel)\n",
    "    if os.path.exists(p):\n",
    "        return p\n",
    "    p2 = os.path.join(root, \"wav\", rel)\n",
    "    if os.path.exists(p2):\n",
    "        return p2\n",
    "    p3 = os.path.join(root, \"wav\", \"wav\", os.path.basename(rel))\n",
    "    return p3\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_embeddings(model, file_list, sr=16000, n_mels=80, batch_size=4):\n",
    "    model.eval()\n",
    "    mel_tf = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sr, n_fft=400, hop_length=160, n_mels=n_mels\n",
    "    )\n",
    "    emb_map = {}\n",
    "    for i in range(0, len(file_list), batch_size):\n",
    "        batch = file_list[i:i+batch_size]\n",
    "        mels = []\n",
    "        valid_paths = []\n",
    "        for path in batch:\n",
    "            try:\n",
    "                wav, sr0 = torchaudio.load(path)\n",
    "                if wav.shape[0] > 1:\n",
    "                    wav = torch.mean(wav, 0, keepdim=True)\n",
    "                if sr0 != sr:\n",
    "                    wav = torchaudio.functional.resample(wav, sr0, sr)\n",
    "                wav = F.pad(wav, (0, max(0, int(3.0 * sr) - wav.size(1))))\n",
    "                wav = wav[:, :int(3.0 * sr)]  \n",
    "                mel = torch.log(mel_tf(wav) + 1e-6).squeeze(0)\n",
    "                mels.append(mel)\n",
    "                valid_paths.append(path)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Lỗi khi đọc {path}: {e}\")\n",
    "                continue\n",
    "\n",
    "        if not mels:\n",
    "            continue\n",
    "        max_T = max(m.shape[1] for m in mels)\n",
    "        mels = [F.pad(m, (0, max_T - m.shape[1])) for m in mels]\n",
    "\n",
    "        mel_batch = torch.stack(mels).to(DEVICE)\n",
    "        emb_batch = model(mel_batch).cpu()\n",
    "        for path, emb in zip(valid_paths, emb_batch):\n",
    "            emb_map[os.path.basename(path)] = emb\n",
    "        if DEVICE == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "    return emb_map\n",
    "\n",
    "\n",
    "BATCH, WORKERS, EPOCHS = 32, 4, 30\n",
    "train_loader = DataLoader(\n",
    "    VoiceDataset(train_set, augment=True),\n",
    "    batch_size=BATCH, shuffle=True,\n",
    "    num_workers=WORKERS, pin_memory=True\n",
    ")\n",
    "\n",
    "model = MFAConformer().to(DEVICE)\n",
    "head  = AAMSoftmax(emb_dim=192, num_classes=num_classes, s=30.0, m=0.2).to(DEVICE)\n",
    "opt   = optim.Adam(list(model.parameters()) + list(head.parameters()), lr=2e-3)\n",
    "steps = len(train_loader)\n",
    "sched = optim.lr_scheduler.OneCycleLR(opt, max_lr=2e-3, epochs=EPOCHS, steps_per_epoch=steps)\n",
    "crit  = nn.CrossEntropyLoss()\n",
    "scaler = GradScaler() if USE_SCALER else None\n",
    "\n",
    "best_eer = 999.0\n",
    "with open(\"train_log.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"epoch\",\"train_loss\",\"train_acc\",\"test_eer\"])\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train(); head.train()\n",
    "        total_loss = 0.0; correct = 0; total = 0\n",
    "\n",
    "        for mel, lbl in train_loader:\n",
    "            mel, lbl = mel.to(DEVICE), lbl.to(DEVICE)\n",
    "            with autocast(device_type=\"cuda\" if DEVICE==\"cuda\" else \"cpu\", dtype=AMP_DTYPE):\n",
    "                emb = model(mel)\n",
    "                logits = head(emb, lbl)\n",
    "                loss = crit(logits, lbl)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            if USE_SCALER:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            sched.step()\n",
    "\n",
    "            total_loss += loss.item() * lbl.size(0)\n",
    "            with torch.no_grad():\n",
    "                preds = logits.argmax(1)\n",
    "            correct    += (preds == lbl).sum().item()\n",
    "            total      += lbl.size(0)\n",
    "\n",
    "        train_loss = total_loss / total\n",
    "        train_acc  = correct / total\n",
    "\n",
    "\n",
    "        all_files = sorted({resolve_test_path(TEST_ROOT, p) for f1, f2, _ in pairs for p in [f1, f2]})\n",
    "        emb_map = extract_embeddings(model, all_files, batch_size=4)\n",
    "        scores, labels = [], []\n",
    "        for f1, f2, label in pairs:\n",
    "            p1, p2 = resolve_test_path(TEST_ROOT, f1), resolve_test_path(TEST_ROOT, f2)\n",
    "            n1, n2 = os.path.basename(p1), os.path.basename(p2)\n",
    "            if n1 not in emb_map or n2 not in emb_map:\n",
    "                print(f\"[WARN] Missing embedding for {n1} or {n2}\")\n",
    "                continue\n",
    "            sim = F.cosine_similarity(\n",
    "                emb_map[n1].unsqueeze(0),\n",
    "                emb_map[n2].unsqueeze(0)\n",
    "            ).item()\n",
    "            scores.append(sim); labels.append(label)\n",
    "        test_eer = compute_eer(scores, labels) if scores else 100.0\n",
    "\n",
    "        print(f\"Epoch {ep:02d} | loss={train_loss:.4f} acc={train_acc:.4f} | test_EER={test_eer:.2f}%\")\n",
    "        writer.writerow([ep, train_loss, train_acc, test_eer]); f.flush()\n",
    "\n",
    "        if test_eer < best_eer:\n",
    "            best_eer = test_eer\n",
    "            torch.save({\"model\": model.state_dict(), \"head\": head.state_dict()}, \"best_model.pt\")\n",
    "            print(\" Saved new best model (by test EER)\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7251391,
     "sourceId": 11565412,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8345362,
     "sourceId": 13169831,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-14T11:42:10.417988",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
