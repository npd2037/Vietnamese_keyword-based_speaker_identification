{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c95a6c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-20T12:52:01.310663Z",
     "iopub.status.busy": "2025-10-20T12:52:01.310388Z",
     "iopub.status.idle": "2025-10-20T19:51:27.285700Z",
     "shell.execute_reply": "2025-10-20T19:51:27.284675Z"
    },
    "papermill": {
     "duration": 25165.98211,
     "end_time": "2025-10-20T19:51:27.289085",
     "exception": false,
     "start_time": "2025-10-20T12:52:01.306975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os, glob, random, csv, time\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch, torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE, \" | Torch:\", torch.__version__, \"| Torchaudio:\", torchaudio.__version__)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "AMP_DTYPE = torch.float16\n",
    "USE_SCALER = True\n",
    "\n",
    "if DEVICE == \"cuda\":\n",
    "    try:\n",
    "        torch.cuda.manual_seed(SEED)\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "    except RuntimeError as e:\n",
    "        print(\" CUDA manual_seed_all() failed, continue with CPU seeds:\", str(e))\n",
    "\n",
    "\n",
    "TRAIN_ROOT = \"/kaggle/input/voxvn-api491/train_small_wav\"\n",
    "TEST_ROOT  = \"/kaggle/input/voxvietnam\"\n",
    "assert os.path.exists(TRAIN_ROOT), \"Không thấy train folder!\"\n",
    "assert os.path.exists(TEST_ROOT),  \"Không thấy test folder!\"\n",
    "\n",
    "\n",
    "def scan_dataset(root):\n",
    "    all_files = glob.glob(os.path.join(root, \"*\", \"*.wav\"))\n",
    "    speakers = sorted(list({os.path.basename(os.path.dirname(f)) for f in all_files}))\n",
    "    spk2idx_raw = {spk: i for i, spk in enumerate(speakers)}\n",
    "    spk2files_raw = defaultdict(list)\n",
    "    for f in all_files:\n",
    "        spk = os.path.basename(os.path.dirname(f))\n",
    "        spk2files_raw[spk2idx_raw[spk]].append(f)\n",
    "    spk2files_raw = {k: v for k, v in spk2files_raw.items() if len(v) >= 2}\n",
    "    return spk2files_raw\n",
    "\n",
    "spk2files_train_raw = scan_dataset(TRAIN_ROOT)\n",
    "spk_list = sorted(list(spk2files_train_raw.keys()))\n",
    "spk_map = {spk: i for i, spk in enumerate(spk_list)}\n",
    "train_set = [(f, spk_map[spk]) for spk, files in spk2files_train_raw.items() for f in files]\n",
    "num_classes = len(spk_map)\n",
    "\n",
    "print(f\" Train dataset: {num_classes} speakers | {len(train_set)} utterances\")\n",
    "labels_dbg = [y for _, y in train_set]\n",
    "print(f\" Label range: {min(labels_dbg)} … {max(labels_dbg)} (num_classes={num_classes})\")\n",
    "\n",
    "\n",
    "def load_voxvietnam_pairs(root):\n",
    "    csv_path = os.path.join(root, \"test_list_gt.csv\")\n",
    "    txt_path = os.path.join(root, \"test_list.txt\")\n",
    "    path = csv_path if os.path.exists(csv_path) else txt_path\n",
    "    assert os.path.exists(path), f\"Không tìm thấy test list: {path}\"\n",
    "\n",
    "    pairs = []\n",
    "    with open(path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        for raw in f:\n",
    "            line = raw.strip()\n",
    "            if not line: \n",
    "                continue\n",
    "            line = line.replace('\"', '').replace(',', ' ').replace('\\t', ' ')\n",
    "            parts = [p for p in line.split() if p]\n",
    "            if len(parts) != 3:\n",
    "                continue\n",
    "            try:\n",
    "                label = int(parts[0]); f1, f2 = parts[1], parts[2]\n",
    "                pairs.append((f1, f2, label))\n",
    "            except:\n",
    "                continue\n",
    "    print(f\" Loaded {len(pairs)} pairs from {os.path.basename(path)}\")\n",
    "    if pairs:\n",
    "        print(\" Ví dụ:\", pairs[0])\n",
    "    return pairs\n",
    "\n",
    "pairs = load_voxvietnam_pairs(TEST_ROOT)\n",
    "\n",
    "def resolve_test_path(root, rel):\n",
    "    p1 = os.path.join(root, rel)\n",
    "    p2 = os.path.join(root, \"wav\", rel)\n",
    "    p3 = os.path.join(root, \"wav\", \"wav\", os.path.basename(rel))\n",
    "    if os.path.exists(p1): return p1\n",
    "    if os.path.exists(p2): return p2\n",
    "    if os.path.exists(p3): return p3\n",
    "    return None\n",
    "\n",
    "class VoiceDataset(Dataset):\n",
    "    def __init__(self, samples, augment=False, sr=16000, max_len=3.0, n_mels=80):\n",
    "        self.samples=samples; self.augment=augment\n",
    "        self.sr=sr; self.max_len=max_len\n",
    "        self.mel_tf=torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=sr, n_fft=400, hop_length=160, n_mels=n_mels)\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        try:\n",
    "            wav, sr0 = torchaudio.load(path)\n",
    "            if wav.shape[0] > 1: wav = wav.mean(0, keepdim=True)\n",
    "            if sr0 != self.sr:   wav = torchaudio.functional.resample(wav, sr0, self.sr)\n",
    "            L = int(self.max_len * self.sr)\n",
    "            if wav.size(1) > L:\n",
    "                st = random.randint(0, wav.size(1)-L)\n",
    "                wav = wav[:, st:st+L]\n",
    "            else:\n",
    "                wav = F.pad(wav, (0, L - wav.size(1)))\n",
    "            if self.augment:\n",
    "                if random.random() < 0.5: wav = wav + 0.005 * torch.randn_like(wav)\n",
    "                if random.random() < 0.5: wav = wav * random.uniform(0.8, 1.2)\n",
    "            mel = torch.log(self.mel_tf(wav) + 1e-6).squeeze(0).transpose(0,1)  \n",
    "            return mel, label\n",
    "        except Exception as e:\n",
    "            print(\"[WARN] lỗi đọc:\", path, e)\n",
    "            return self.__getitem__((idx+1) % len(self.samples))\n",
    "\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, c, r=8):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv1d(c, c//r, 1), nn.ReLU(), nn.Conv1d(c//r, c, 1), nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        s = self.pool(x)\n",
    "        return x * self.fc(s)\n",
    "\n",
    "class Res2Block(nn.Module):\n",
    "    def __init__(self, c=512, scale=8, k=3, d=2):\n",
    "        super().__init__()\n",
    "        w = c // scale\n",
    "        self.scale = scale\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(w, w, k, padding=d, dilation=d, bias=False) for _ in range(scale-1)\n",
    "        ])\n",
    "        self.bn = nn.BatchNorm1d(c)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        splits = torch.chunk(x, self.scale, 1)\n",
    "        out = []\n",
    "        for i in range(self.scale):\n",
    "            if i == 0: out.append(splits[i])\n",
    "            else:\n",
    "                s = splits[i] + out[i-1]\n",
    "                s = self.convs[i-1](s)\n",
    "                out.append(s)\n",
    "        out = torch.cat(out, 1)\n",
    "        return self.bn(self.relu(out))\n",
    "\n",
    "class ECAPA_TDNN(nn.Module):\n",
    "    def __init__(self, n_mels=80, c=512, emb=192):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(n_mels, c, kernel_size=5, padding=2, bias=False),\n",
    "            nn.ReLU(), nn.BatchNorm1d(c))\n",
    "        self.blocks, self.proj, self.se = nn.ModuleList(), nn.ModuleList(), nn.ModuleList()\n",
    "        for d in [2,3,4]:\n",
    "            self.blocks.append(Res2Block(c, scale=8, d=d))\n",
    "            self.proj.append(nn.Conv1d(c, c, 1, bias=False))\n",
    "            self.se.append(SEBlock(c, 8))\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Conv1d(c*3, 128, 1), nn.ReLU(), nn.BatchNorm1d(128),\n",
    "            nn.Conv1d(128, c*3, 1), nn.Softmax(dim=2))\n",
    "        self.fc = nn.Linear((c*3)*2, emb)\n",
    "    def forward(self, x):          \n",
    "        x = x.transpose(1,2)      \n",
    "        x = self.layer1(x)\n",
    "        feats = []; h = x\n",
    "        for blk, prj, se in zip(self.blocks, self.proj, self.se):\n",
    "            y = blk(h); y = se(prj(y)) + h\n",
    "            feats.append(y); h = y\n",
    "        cat = torch.cat(feats, 1) \n",
    "        w = self.attn(cat)\n",
    "        mean = torch.sum(cat*w, 2)\n",
    "        std  = torch.sqrt(torch.sum((cat**2)*w, 2) - mean**2 + 1e-6)\n",
    "        out = torch.cat([mean, std], 1)\n",
    "        emb = self.fc(out)\n",
    "        return F.normalize(emb, p=2, dim=1)\n",
    "\n",
    "class AAMSoftmaxHead(nn.Module):\n",
    "    def __init__(self, emb, n_class, s=30.0, m=0.2):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.randn(n_class, emb))\n",
    "        nn.init.xavier_uniform_(self.W)\n",
    "        self.s, self.m = s, m\n",
    "    def forward(self, x, y=None):\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        W = F.normalize(self.W, p=2, dim=1)\n",
    "        logits = F.linear(x, W)\n",
    "        if y is not None:\n",
    "            idx = torch.arange(x.size(0), device=x.device)\n",
    "            cos_y = logits[idx, y].clamp(-1,1)\n",
    "            theta = torch.acos(cos_y)\n",
    "            logits[idx, y] = torch.cos(theta + self.m).to(logits.dtype)\n",
    "        return logits * self.s\n",
    "\n",
    "\n",
    "def compute_eer(scores, labels):\n",
    "    fpr, tpr, _ = roc_curve(labels, scores)\n",
    "    fnr = 1 - tpr\n",
    "    idx = np.nanargmin(np.abs(fnr - fpr))\n",
    "    return float(fpr[idx] * 100)\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_embeddings(model, files, sr=16000, batch_size=4):\n",
    "    model.eval()\n",
    "    mel_tf = torchaudio.transforms.MelSpectrogram(sr, n_fft=400, hop_length=160, n_mels=80)\n",
    "    emb_map = {}\n",
    "    for i in range(0, len(files), batch_size):\n",
    "        batch = files[i:i+batch_size]\n",
    "        mels = []\n",
    "        for f in batch:\n",
    "            try:\n",
    "                wav, sr0 = torchaudio.load(f)\n",
    "                if wav.shape[0] > 1: wav = wav.mean(0, keepdim=True)\n",
    "                if sr0 != sr: wav = torchaudio.functional.resample(wav, sr0, sr)\n",
    "                wav = F.pad(wav, (0, max(0, int(3*sr) - wav.size(1))))[:, :int(3*sr)]\n",
    "                mel = torch.log(mel_tf(wav) + 1e-6).squeeze(0).transpose(0,1) \n",
    "                mels.append(mel)\n",
    "            except Exception as e:\n",
    "                print(\"[WARN] extract:\", f, e)\n",
    "        if not mels: \n",
    "            continue\n",
    "        max_T = max(m.shape[0] for m in mels)\n",
    "        mels = [F.pad(m, (0,0, 0, max_T - m.shape[0])) for m in mels]  \n",
    "        mel_batch = torch.stack(mels).to(DEVICE)\n",
    "        emb_batch = model(mel_batch).cpu()\n",
    "        for fpath, emb in zip(batch, emb_batch):\n",
    "            emb_map[os.path.basename(fpath)] = emb\n",
    "        torch.cuda.empty_cache()\n",
    "    return emb_map\n",
    "\n",
    "\n",
    "BATCH, EPOCHS = 32, 40\n",
    "train_loader = DataLoader(\n",
    "    VoiceDataset(train_set, augment=True),\n",
    "    batch_size=BATCH, shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "model = ECAPA_TDNN().to(DEVICE)\n",
    "head  = AAMSoftmaxHead(192, num_classes).to(DEVICE)\n",
    "opt   = optim.AdamW(list(model.parameters())+list(head.parameters()), lr=3e-4, weight_decay=1e-4)\n",
    "sch   = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS, eta_min=1e-5)\n",
    "crit  = nn.CrossEntropyLoss()\n",
    "scaler = GradScaler(enabled=USE_SCALER)\n",
    "\n",
    "best_eer = 999.0\n",
    "with open(\"train_log.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f); writer.writerow([\"epoch\",\"loss\",\"acc\",\"eer\"])\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train(); head.train()\n",
    "        tot_loss=0.0; correct=0; total=0\n",
    "        t0 = time.time()\n",
    "        for mel, lbl in train_loader:\n",
    "            mel, lbl = mel.to(DEVICE), lbl.to(DEVICE)\n",
    "            with autocast(device_type=\"cuda\" if DEVICE==\"cuda\" else \"cpu\", dtype=AMP_DTYPE):\n",
    "                emb = model(mel)\n",
    "                logits = head(emb, lbl)\n",
    "                loss = crit(logits, lbl)\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(\" NaN/Inf loss — skip batch\")\n",
    "                continue\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            if USE_SCALER:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(list(model.parameters())+list(head.parameters()), 5.0)\n",
    "                scaler.step(opt); scaler.update()\n",
    "            else:\n",
    "                loss.backward(); opt.step()\n",
    "            tot_loss += loss.item() * lbl.size(0)\n",
    "            correct  += (logits.argmax(1) == lbl).sum().item()\n",
    "            total    += lbl.size(0)\n",
    "        sch.step()\n",
    "        tr_loss, tr_acc = tot_loss/total, correct/total\n",
    "\n",
    "        all_files = sorted({resolve_test_path(TEST_ROOT, p)\n",
    "                           for f1, f2, _ in pairs for p in [f1, f2]\n",
    "                           if resolve_test_path(TEST_ROOT, p)})\n",
    "        emb_map = extract_embeddings(model, all_files)\n",
    "        scores, labels = [], []\n",
    "        for f1, f2, lab in pairs:\n",
    "            p1 = resolve_test_path(TEST_ROOT, f1)\n",
    "            p2 = resolve_test_path(TEST_ROOT, f2)\n",
    "            if not p1 or not p2: continue\n",
    "            n1, n2 = os.path.basename(p1), os.path.basename(p2)\n",
    "            if n1 not in emb_map or n2 not in emb_map: continue\n",
    "            sim = F.cosine_similarity(emb_map[n1].unsqueeze(0), emb_map[n2].unsqueeze(0)).item()\n",
    "            scores.append(sim); labels.append(lab)\n",
    "        eer = compute_eer(scores, labels) if scores else 100.0\n",
    "\n",
    "        t1 = time.time()\n",
    "        print(f\"Epoch {ep:02d} | loss={tr_loss:.4f} acc={tr_acc:.4f} | test_EER={eer:.2f}% | {t1-t0:.1f}s\")\n",
    "        writer.writerow([ep, tr_loss, tr_acc, eer]); f.flush()\n",
    "\n",
    "        if eer < best_eer:\n",
    "            best_eer = eer\n",
    "            torch.save({\"model\": model.state_dict(), \"head\": head.state_dict()}, \"best_model.pt\")\n",
    "            print(\" Saved new best model\")\n",
    "\n",
    "print(f\" Done | Best EER={best_eer:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7251391,
     "sourceId": 11565412,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8345362,
     "sourceId": 13169831,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25172.447063,
   "end_time": "2025-10-20T19:51:30.036752",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-20T12:51:57.589689",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
