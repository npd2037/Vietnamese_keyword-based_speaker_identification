{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-22T08:11:41.010644Z",
     "iopub.status.busy": "2025-10-22T08:11:41.010382Z",
     "iopub.status.idle": "2025-10-22T08:12:00.445934Z",
     "shell.execute_reply": "2025-10-22T08:12:00.445256Z",
     "shell.execute_reply.started": "2025-10-22T08:11:41.010621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -U transformers huggingface_hub httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T08:12:00.447896Z",
     "iopub.status.busy": "2025-10-22T08:12:00.447628Z",
     "iopub.status.idle": "2025-10-22T08:12:36.212212Z",
     "shell.execute_reply": "2025-10-22T08:12:36.211551Z",
     "shell.execute_reply.started": "2025-10-22T08:12:00.447875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets as dt\n",
    "import torchvision as tv\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as pt\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from transformers import Wav2Vec2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T08:12:36.213457Z",
     "iopub.status.busy": "2025-10-22T08:12:36.212926Z",
     "iopub.status.idle": "2025-10-22T08:13:07.960214Z",
     "shell.execute_reply": "2025-10-22T08:13:07.959346Z",
     "shell.execute_reply.started": "2025-10-22T08:12:36.213439Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def collect_audio_list(root_fpt, root_edge, root_cut):\n",
    "    data = []\n",
    "\n",
    "    for sub in [\"false_no\", \"false_yes\", \"true\"]:\n",
    "        sub_path = Path(root_fpt) / sub\n",
    "        if not sub_path.exists():\n",
    "            continue\n",
    "\n",
    "        label = 1 if sub == \"true\" else 0\n",
    "\n",
    "        for speaker_dir in sub_path.iterdir():\n",
    "            if not speaker_dir.is_dir():\n",
    "                continue\n",
    "            for wav in speaker_dir.glob(\"*.wav\"):\n",
    "                data.append((str(wav), label))\n",
    "\n",
    "    edge_root = Path(root_edge)\n",
    "    for speaker_dir in edge_root.iterdir():\n",
    "        if not speaker_dir.is_dir():\n",
    "            continue\n",
    "        for sub in speaker_dir.iterdir():\n",
    "            if not sub.is_dir():\n",
    "                continue\n",
    "            label = 1 if sub.name.lower() == \"true\" else 0\n",
    "            for mp3 in sub.glob(\"*.mp3\"):\n",
    "                data.append((str(mp3), label))\n",
    "\n",
    "    cut_root = Path(root_cut)\n",
    "    for mp3 in cut_root.glob(\"*.mp3\"):\n",
    "        data.append((str(mp3), 0))\n",
    "\n",
    "    return data\n",
    "\n",
    "root_fpt = \"/kaggle/input/voice-fpt-aip491/Data_voices/Data_voices/FPT.AI\"\n",
    "root_edge = \"/kaggle/input/voice-fpt-aip491/Data_voices/Data_voices/edge_voices_16k\"\n",
    "root_cut = \"/kaggle/input/voice-fpt-aip491/Data_voices/Data_voices/cut_sound\"\n",
    "\n",
    "data_train = collect_audio_list(root_fpt, root_edge, root_cut)\n",
    "\n",
    "random.seed(35)\n",
    "random.shuffle(data_train)\n",
    "\n",
    "n_total = len(data_train)\n",
    "n_valid = int(0.1 * n_total)\n",
    "\n",
    "data_valid = data_train[:n_valid]\n",
    "data_train = data_train[n_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T08:13:07.962386Z",
     "iopub.status.busy": "2025-10-22T08:13:07.962154Z",
     "iopub.status.idle": "2025-10-22T08:13:08.132743Z",
     "shell.execute_reply": "2025-10-22T08:13:08.132063Z",
     "shell.execute_reply.started": "2025-10-22T08:13:07.962369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collect_test_audio_list(root_test):\n",
    "    data = []\n",
    "    root_test = Path(root_test)\n",
    "\n",
    "    for speaker_dir in root_test.iterdir():\n",
    "        if not speaker_dir.is_dir():\n",
    "            continue\n",
    "        for sub_dir in speaker_dir.iterdir():\n",
    "            if not sub_dir.is_dir():\n",
    "                continue\n",
    "\n",
    "            label = 1 if sub_dir.name.lower() == \"true\" else 0\n",
    "\n",
    "            for audio_file in sub_dir.glob(\"*.mp3\"):\n",
    "                data.append((str(audio_file), label))\n",
    "            for audio_file in sub_dir.glob(\"*.wav\"):\n",
    "                data.append((str(audio_file), label))\n",
    "\n",
    "    print(f\"{sum(l for _, l in data)} label=1, {len(data)-sum(l for _, l in data)} label=0\")\n",
    "    return data\n",
    "\n",
    "\n",
    "root_test = \"/kaggle/input/test-aip419/Datatest\"\n",
    "data_test = collect_test_audio_list(root_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T08:13:08.133769Z",
     "iopub.status.busy": "2025-10-22T08:13:08.133473Z",
     "iopub.status.idle": "2025-10-22T08:13:08.141189Z",
     "shell.execute_reply": "2025-10-22T08:13:08.140588Z",
     "shell.execute_reply.started": "2025-10-22T08:13:08.133743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SpeakerClassificationDataset(Dataset):\n",
    "    def __init__(self, data, fixed_len=40000, sample_rate=16000, one_hot=False):\n",
    "        self.data = data\n",
    "        self.fixed_len = fixed_len\n",
    "        self.sample_rate = sample_rate\n",
    "        self.one_hot = one_hot\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, spk_id = self.data[idx]\n",
    "        wav, _ = torchaudio.load(path)\n",
    "        wav = wav.mean(dim=0)  # mono\n",
    "        wav = self._fix_length(wav)\n",
    "\n",
    "        if self.one_hot:\n",
    "            label = pt.zeros(self.num_speakers, dtype=pt.float32)\n",
    "            label[spk_id] = 1.0\n",
    "        else:\n",
    "            label = spk_id\n",
    "\n",
    "        return wav, label\n",
    "\n",
    "    def _fix_length(self, wav):\n",
    "        L = wav.size(0)\n",
    "        if L > self.fixed_len:\n",
    "            wav = wav[:self.fixed_len]\n",
    "        elif L < self.fixed_len:\n",
    "            pad_len = self.fixed_len - L\n",
    "            wav = torch.nn.functional.pad(wav, (0, pad_len))\n",
    "        return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T08:13:08.142131Z",
     "iopub.status.busy": "2025-10-22T08:13:08.141856Z",
     "iopub.status.idle": "2025-10-22T08:13:08.169209Z",
     "shell.execute_reply": "2025-10-22T08:13:08.168551Z",
     "shell.execute_reply.started": "2025-10-22T08:13:08.142090Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "class Wav2Vec2ID(nn.Module):\n",
    "    def __init__(self, hidden_size=150, num_classes=900, freeze_encoder=True):\n",
    "        super().__init__()\n",
    "        from transformers import Wav2Vec2Model\n",
    "        self.encoder = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "        if freeze_encoder:\n",
    "            for p in self.encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "        self.fc_hidden = nn.Sequential(\n",
    "            nn.Linear(self.encoder.config.hidden_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x).last_hidden_state   # [B, T', H]\n",
    "        pooled = out.mean(dim=1)\n",
    "        emb = self.fc_hidden(pooled)\n",
    "        logits = self.fc_out(emb)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T08:13:08.170424Z",
     "iopub.status.busy": "2025-10-22T08:13:08.170191Z",
     "iopub.status.idle": "2025-10-22T08:13:08.195987Z",
     "shell.execute_reply": "2025-10-22T08:13:08.195043Z",
     "shell.execute_reply.started": "2025-10-22T08:13:08.170408Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import time\n",
    "\n",
    "def train_one_epo(loader, model, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for xb, yb in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        xb, yb = xb.to(device), yb.to(device).float().unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "        preds = pt.sigmoid(outputs).round().cpu().detach().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    return total_loss / len(loader.dataset), acc\n",
    "\n",
    "\n",
    "def valid_at_epo(loader, model, criterion, device, threshold= 0.5):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    batch_times = []\n",
    "\n",
    "    with pt.no_grad():\n",
    "        for xb, yb in tqdm(loader, desc=\"Valid\", leave=False):\n",
    "            xb, yb = xb.to(device), yb.to(device).float().unsqueeze(1)\n",
    "\n",
    "            start = time.time()\n",
    "            outputs = model(xb)\n",
    "            end = time.time()\n",
    "            batch_times.append(end - start)\n",
    "\n",
    "            loss = criterion(outputs, yb)\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "            probs = pt.sigmoid(outputs).cpu().numpy()\n",
    "            preds = (probs >= threshold).astype(int)\n",
    "\n",
    "            all_probs.extend(probs)\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    avg_forward_time = sum(batch_times) / len(batch_times) if batch_times else 0.0\n",
    "    return total_loss / len(loader.dataset), acc, auc, f1, avg_forward_time\n",
    "\n",
    "def valid_at_epo_t(loader, model, criterion, device, step=0.01):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_labels, all_probs = [], []\n",
    "    batch_times = []\n",
    "\n",
    "    with pt.no_grad():\n",
    "        for xb, yb in tqdm(loader, desc=\"Test\", leave=False):\n",
    "            xb, yb = xb.to(device), yb.to(device).float().unsqueeze(1)\n",
    "\n",
    "            start = time.time()\n",
    "            outputs = model(xb)\n",
    "            end = time.time()\n",
    "            batch_times.append(end - start)\n",
    "\n",
    "            loss = criterion(outputs, yb)\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "            probs = pt.sigmoid(outputs).cpu().numpy()\n",
    "            all_probs.extend(probs)\n",
    "            all_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "    thresholds = [i * step for i in range(int(1 / step) + 1)]\n",
    "    best_s, best_f1, best_thr, best_acc = 0, 0, 0.5, 0\n",
    "\n",
    "    for thr in thresholds:\n",
    "        preds = (pt.tensor(all_probs) >= thr).int().numpy()\n",
    "        f1 = f1_score(all_labels, preds)\n",
    "        acc = accuracy_score(all_labels, preds)\n",
    "        if f1*acc > best_s:\n",
    "            best_f1, best_thr, best_acc = f1, thr, acc\n",
    "            best_s = f1*acc\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_probs)\n",
    "    except ValueError:\n",
    "        auc = float(\"nan\")\n",
    "\n",
    "    avg_forward_time = sum(batch_times) / len(batch_times) if batch_times else 0.0\n",
    "\n",
    "    return total_loss / len(loader.dataset), best_acc, auc, best_f1, best_thr, avg_forward_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_s = 110\n",
    "\n",
    "tra_ds = SpeakerClassificationDataset(data_train, fixed_len=40000, sample_rate=16000)\n",
    "tra_dl = DataLoader(tra_ds, batch_size=batch_s, shuffle=True)\n",
    "\n",
    "val_ds = SpeakerClassificationDataset(data_valid, fixed_len=40000, sample_rate=16000)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_s, shuffle=False)\n",
    "\n",
    "tes_ds = SpeakerClassificationDataset(data_test, fixed_len=40000, sample_rate=16000)\n",
    "tes_dl = DataLoader(tes_ds, batch_size=batch_s, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T08:13:08.218859Z",
     "iopub.status.busy": "2025-10-22T08:13:08.218619Z",
     "iopub.status.idle": "2025-10-22T08:13:11.927776Z",
     "shell.execute_reply": "2025-10-22T08:13:11.926969Z",
     "shell.execute_reply.started": "2025-10-22T08:13:08.218841Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n",
    "model = Wav2Vec2ID(num_classes=1, freeze_encoder=True).to(device)\n",
    "optimizer = pt.optim.Adam(model.parameters(), lr=2e-4)\n",
    "criterion = pt.nn.BCEWithLogitsLoss()\n",
    "\n",
    "list_name = []\n",
    "list_tr_lo = list()\n",
    "list_tr_ac = list()\n",
    "list_va_lo = list()\n",
    "list_va_ac = list()\n",
    "list_va_au = list()\n",
    "list_va_f1 = list()\n",
    "list_va_ti = list()\n",
    "list_te_ac = list()\n",
    "list_te_au = list()\n",
    "list_te_f1 = list()\n",
    "list_te_b_ac = list()\n",
    "list_te_b_au = list()\n",
    "list_te_b_f1 = list()\n",
    "list_te_b_th = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T08:13:17.401039Z",
     "iopub.status.busy": "2025-10-22T08:13:17.400707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for tn in range(25):\n",
    "\n",
    "    print(tn)\n",
    "\n",
    "    if tn == 1:\n",
    "        for p in model.encoder.parameters():\n",
    "            p.requires_grad = True\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=4e-5)\n",
    "        \n",
    "    train_loss, train_acc = train_one_epo(tra_dl, model, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc, valid_auc, valid_f1, valid_time = valid_at_epo(val_dl, model, criterion, device, 0.5)\n",
    "    _, test_acc, test_auc, test_f1, _ = valid_at_epo(tes_dl, model, criterion, device, 0.5)\n",
    "    _, test_b_acc, test_b_auc, test_b_f1, test_b_thr, _ = valid_at_epo_t(tes_dl, model, criterion, device)\n",
    "    \n",
    "\n",
    "    list_tr_lo.append(train_loss)\n",
    "    list_tr_ac.append(train_acc)\n",
    "    \n",
    "    list_va_lo.append(valid_loss)\n",
    "    list_va_ac.append(valid_acc)\n",
    "    list_va_au.append(valid_auc)\n",
    "    list_va_f1.append(valid_f1)\n",
    "    list_va_ti.append(valid_time)\n",
    "\n",
    "    list_te_ac.append(test_acc)\n",
    "    list_te_au.append(test_auc)\n",
    "    list_te_f1.append(test_f1)\n",
    "    \n",
    "    list_te_b_ac.append(test_b_acc)\n",
    "    list_te_b_au.append(test_b_auc)\n",
    "    list_te_b_f1.append(test_b_f1)\n",
    "    list_te_b_th.append(test_b_thr)\n",
    "\n",
    "    print(f\"  Train -> loss: {train_loss:.4f}, acc: {train_acc:.4f}\")\n",
    "    print(f\"  Valid -> loss: {valid_loss:.4f}, acc: {valid_acc:.4f}, auc: {valid_auc:.4f}, f1: {valid_f1:.4f}, time: {valid_time:.4f}s\")\n",
    "    print(f\"  Test -> acc: {test_acc:.4f}, auc: {test_auc:.4f}, f1: {test_f1:.4f}\")\n",
    "    print(f\"  Test best  -> acc: {test_b_acc:.4f}, auc: {test_b_auc:.4f}, f1: {test_b_f1:.4f}, th: {test_b_thr:.2f}\")\n",
    "    os.makedirs(\"w2v\", exist_ok=True)\n",
    "    pt.save(model.state_dict(), \"w2v/\" + str(tn) + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8250661,
     "sourceId": 13040120,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8511916,
     "sourceId": 13411965,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
