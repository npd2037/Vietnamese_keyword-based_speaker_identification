{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T17:29:03.873179Z",
     "iopub.status.busy": "2025-11-14T17:29:03.873000Z",
     "iopub.status.idle": "2025-11-14T17:29:16.993534Z",
     "shell.execute_reply": "2025-11-14T17:29:16.992500Z",
     "shell.execute_reply.started": "2025-11-14T17:29:03.873162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!apt-get install -y sox libsox-dev libsox-fmt-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-14T17:29:16.995771Z",
     "iopub.status.busy": "2025-11-14T17:29:16.995540Z",
     "iopub.status.idle": "2025-11-14T17:29:24.783985Z",
     "shell.execute_reply": "2025-11-14T17:29:24.783323Z",
     "shell.execute_reply.started": "2025-11-14T17:29:16.995746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import os\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T17:29:24.785149Z",
     "iopub.status.busy": "2025-11-14T17:29:24.784791Z",
     "iopub.status.idle": "2025-11-14T17:29:43.889483Z",
     "shell.execute_reply": "2025-11-14T17:29:43.888782Z",
     "shell.execute_reply.started": "2025-11-14T17:29:24.785124Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def collect_audio_list(root_fpt, root_edge, root_cut):\n",
    "    data = []\n",
    "\n",
    "    for sub in [\"false_no\", \"false_yes\", \"true\"]:\n",
    "        sub_path = Path(root_fpt) / sub\n",
    "        if not sub_path.exists():\n",
    "            continue\n",
    "\n",
    "        label = 1 if sub == \"true\" else 0\n",
    "\n",
    "        for speaker_dir in sub_path.iterdir():\n",
    "            if not speaker_dir.is_dir():\n",
    "                continue\n",
    "            for wav in speaker_dir.glob(\"*.wav\"):\n",
    "                data.append((str(wav), label))\n",
    "\n",
    "    edge_root = Path(root_edge)\n",
    "    for speaker_dir in edge_root.iterdir():\n",
    "        if not speaker_dir.is_dir():\n",
    "            continue\n",
    "        for sub in speaker_dir.iterdir():\n",
    "            if not sub.is_dir():\n",
    "                continue\n",
    "            label = 1 if sub.name.lower() == \"true\" else 0\n",
    "            for mp3 in sub.glob(\"*.mp3\"):\n",
    "                data.append((str(mp3), label))\n",
    "\n",
    "    cut_root = Path(root_cut)\n",
    "    for mp3 in cut_root.glob(\"*.mp3\"):\n",
    "        data.append((str(mp3), 0))\n",
    "\n",
    "    print(f\"Tổng cộng {len(data)} file — {sum(l for _, l in data)} label=1, {len(data)-sum(l for _, l in data)} label=0\")\n",
    "    return data\n",
    "\n",
    "root_fpt = \"/kaggle/input/voice-fpt-aip491/Data_voices/Data_voices/FPT.AI\"\n",
    "root_edge = \"/kaggle/input/voice-fpt-aip491/Data_voices/Data_voices/edge_voices_16k\"\n",
    "root_cut = \"/kaggle/input/voice-fpt-aip491/Data_voices/Data_voices/cut_sound\"\n",
    "\n",
    "data_train = collect_audio_list(root_fpt, root_edge, root_cut)\n",
    "\n",
    "random.seed(35)\n",
    "random.shuffle(data_train)\n",
    "\n",
    "n_total = len(data_train)\n",
    "n_valid = int(0.05 * n_total)\n",
    "\n",
    "data_valid = data_train[:n_valid]\n",
    "data_train = data_train[n_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T17:29:43.920311Z",
     "iopub.status.busy": "2025-11-14T17:29:43.920095Z",
     "iopub.status.idle": "2025-11-14T17:29:44.095337Z",
     "shell.execute_reply": "2025-11-14T17:29:44.094507Z",
     "shell.execute_reply.started": "2025-11-14T17:29:43.920286Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collect_test_audio_list(root_test):\n",
    "    data = []\n",
    "    root_test = Path(root_test)\n",
    "\n",
    "    for speaker_dir in root_test.iterdir():\n",
    "        if not speaker_dir.is_dir():\n",
    "            continue\n",
    "        for sub_dir in speaker_dir.iterdir():\n",
    "            if not sub_dir.is_dir():\n",
    "                continue\n",
    "\n",
    "            label = 1 if sub_dir.name.lower() == \"true\" else 0\n",
    "\n",
    "            for audio_file in sub_dir.glob(\"*.mp3\"):\n",
    "                data.append((str(audio_file), label))\n",
    "            for audio_file in sub_dir.glob(\"*.wav\"):\n",
    "                data.append((str(audio_file), label))\n",
    "\n",
    "    print(f\"Tổng cộng {len(data)} file — {sum(l for _, l in data)} label=1, {len(data)-sum(l for _, l in data)} label=0\")\n",
    "    return data\n",
    "\n",
    "\n",
    "root_test = \"/kaggle/input/test-aip419/Datatest\"\n",
    "data_test = collect_test_audio_list(root_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T18:00:21.123204Z",
     "iopub.status.busy": "2025-11-14T18:00:21.122678Z",
     "iopub.status.idle": "2025-11-14T18:00:21.146831Z",
     "shell.execute_reply": "2025-11-14T18:00:21.146249Z",
     "shell.execute_reply.started": "2025-11-14T18:00:21.123180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def swish(x): return x * torch.sigmoid(x)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, expansion=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, dim * expansion)\n",
    "        self.fc2 = nn.Linear(dim * expansion, dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.act = swish\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, H]\n",
    "        out = self.fc1(x)\n",
    "        out = self.act(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class ConvModule(nn.Module):\n",
    "    def __init__(self, dim, kernel_size=31, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm(dim)\n",
    "        self.pointwise1 = nn.Linear(dim, dim*2)\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.depthwise = nn.Conv1d(dim, dim, kernel_size, padding=padding, groups=dim)\n",
    "        self.bn = nn.BatchNorm1d(dim)\n",
    "        self.pointwise2 = nn.Linear(dim, dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.act = swish\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, H]\n",
    "        out = self.layer_norm(x)\n",
    "        out = self.pointwise1(out)\n",
    "        out = F.glu(out, dim=-1)\n",
    "        out = out.transpose(1, 2)\n",
    "        out = self.depthwise(out)\n",
    "        out = self.bn(out)\n",
    "        out = out.transpose(1, 2)\n",
    "        out = self.act(out)\n",
    "        out = self.pointwise2(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class BinaryGate(nn.Module):\n",
    "    def __init__(self, H):\n",
    "        super().__init__()\n",
    "        self.logits = nn.Linear(H, 2)  # [keep, skip]\n",
    "\n",
    "    def forward(self, x_mean, tau=1.0, training=True, thresh=0.5):\n",
    "        # x_mean: [B, H]\n",
    "        logits = self.logits(x_mean)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        if training:\n",
    "            g = F.gumbel_softmax(logits, tau=tau, hard=True, dim=-1)\n",
    "            keep = g[:, 0].unsqueeze(-1)  # [B,1]\n",
    "            return keep, probs\n",
    "        else:\n",
    "            keep = (probs[:, 0] > thresh).float().unsqueeze(-1)\n",
    "            return keep, probs\n",
    "\n",
    "\n",
    "class ConformerBlockWithGates(nn.Module):\n",
    "    def __init__(self, dim, nhead=4, ff_expansion=4, conv_kernel=31, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.ff1 = FeedForward(dim, expansion=ff_expansion, dropout=dropout)\n",
    "        self.attn_ln = nn.LayerNorm(dim)\n",
    "        self.mhsa = nn.MultiheadAttention(embed_dim=dim, num_heads=nhead, batch_first=True, dropout=dropout)\n",
    "        self.conv = ConvModule(dim, kernel_size=conv_kernel, dropout=dropout)\n",
    "        self.ff2 = FeedForward(dim, expansion=ff_expansion, dropout=dropout)\n",
    "        \n",
    "        self.g_ff1 = BinaryGate(dim)\n",
    "        self.g_attn = BinaryGate(dim)\n",
    "        self.g_conv = BinaryGate(dim)\n",
    "        self.g_ff2 = BinaryGate(dim)\n",
    "        \n",
    "        self.ff_scale = 0.5\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x, tau=1.0, training=True):\n",
    "        # x: [B, T, H]\n",
    "        B, T, H = x.size()\n",
    "        out = x\n",
    "\n",
    "        x_mean = out.mean(dim=1)\n",
    "        keep, p_ff1 = self.g_ff1(x_mean, tau=tau, training=training)\n",
    "        module_out = self.ff1(out)\n",
    "        keep = keep.unsqueeze(1)\n",
    "        out = out + keep * (self.ff_scale * module_out)\n",
    "\n",
    "        x_mean = out.mean(dim=1)\n",
    "        keep, p_attn = self.g_attn(x_mean, tau=tau, training=training)\n",
    "        q = self.attn_ln(out)\n",
    "        attn_out, _ = self.mhsa(q, q, q, need_weights=False)\n",
    "        keep = keep.unsqueeze(1)\n",
    "        out = out + keep * self.dropout(attn_out)\n",
    "\n",
    "        x_mean = out.mean(dim=1)\n",
    "        keep, p_conv = self.g_conv(x_mean, tau=tau, training=training)\n",
    "        conv_out = self.conv(out)\n",
    "        keep = keep.unsqueeze(1)\n",
    "        out = out + keep * conv_out\n",
    "\n",
    "        x_mean = out.mean(dim=1)\n",
    "        keep, p_ff2 = self.g_ff2(x_mean, tau=tau, training=training)\n",
    "        module_out = self.ff2(out)\n",
    "        keep = keep.unsqueeze(1)\n",
    "        out = out + keep * (self.ff_scale * module_out)\n",
    "\n",
    "        out = self.layer_norm(out)\n",
    "        probs = {\"ff1\": p_ff1, \"attn\": p_attn, \"conv\": p_conv, \"ff2\": p_ff2}\n",
    "        return out, probs\n",
    "\n",
    "\n",
    "class SubsampleConv(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_dim=80, n_mels=40):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_dim, kernel_size=(3,3), stride=(1,4), padding=(1,1), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_dim)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_dim, out_dim, kernel_size=(3,3), stride=(1,2), padding=(1,1), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_dim)\n",
    "\n",
    "        self.conv_collapse = nn.Conv2d(out_dim, out_dim, kernel_size=(n_mels, 1), stride=(1,1), bias=False)\n",
    "        self.bn_collapse = nn.BatchNorm2d(out_dim)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.act(self.bn1(self.conv1(x)))\n",
    "        out = self.act(self.bn2(self.conv2(out)))\n",
    "        out = self.act(self.bn_collapse(self.conv_collapse(out)))\n",
    "        out = out.squeeze(2)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConformerEncoderWithGates(nn.Module):\n",
    "    def __init__(self, input_n_mels=40, hidden_dim=80, num_blocks=8,\n",
    "                 nhead=4, ff_expansion=4, conv_kernel=31, dropout=0.1,\n",
    "                 agg=(2, 4, 6)):\n",
    "        super().__init__()\n",
    "        self.agg = set(agg)\n",
    "        self.subsample = SubsampleConv(in_channels=1, out_dim=hidden_dim, n_mels=input_n_mels)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ConformerBlockWithGates(hidden_dim, nhead=nhead, ff_expansion=ff_expansion,\n",
    "                                    conv_kernel=conv_kernel, dropout=dropout)\n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, tau=1.0, training=True):\n",
    "        out = self.subsample(x)               # [B, T', H]\n",
    "        gate_probs = []\n",
    "\n",
    "        for i, blk in enumerate(self.blocks, 1):\n",
    "            out, probs = blk(out, tau=tau, training=training)\n",
    "            gate_probs.append(probs)\n",
    "\n",
    "        return out, gate_probs\n",
    "\n",
    "\n",
    "class ConformerWithGates(nn.Module):\n",
    "    def __init__(self, num_classes=None, n_mels=40, hidden_dim=80, num_blocks=8,\n",
    "                 nhead=4, ff_expansion=4, conv_kernel=31, dropout=0.1, emb_dim=192):\n",
    "        super().__init__()\n",
    "        self.encoder = ConformerEncoderWithGates(\n",
    "            input_n_mels=n_mels,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_blocks=num_blocks,\n",
    "            nhead=nhead,\n",
    "            ff_expansion=ff_expansion,\n",
    "            conv_kernel=conv_kernel,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.emb_dim = emb_dim\n",
    "        self.post = nn.Linear(hidden_dim, emb_dim)\n",
    "        self.bn = nn.BatchNorm1d(emb_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(emb_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, tau=1.0, training=True):\n",
    "        feats, gate_probs = self.encoder(x, tau=tau, training=training)\n",
    "        mean = feats.mean(1)\n",
    "\n",
    "        emb = self.bn(self.post(mean))\n",
    "        emb = F.normalize(torch.nan_to_num(emb), p=2, dim=1)\n",
    "        emb = self.dropout(emb)\n",
    "\n",
    "        logits = self.classifier(emb)\n",
    "        return emb, logits, gate_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def train_one_epo(loader, model, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for xb, yb in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        xb, yb = xb.to(device), yb.to(device).float().unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        _, logits, _ = model(xb)   # (emb, logits, gate_probs)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "        probs = pt.sigmoid(logits).detach().cpu().numpy()\n",
    "        preds = (probs >= 0.5).astype(int)\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    return total_loss / len(loader.dataset), acc\n",
    "\n",
    "\n",
    "def valid_at_epo(loader, model, criterion, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    batch_times = []\n",
    "\n",
    "    with pt.no_grad():\n",
    "        for xb, yb in tqdm(loader, desc=\"Valid\", leave=False):\n",
    "            xb, yb = xb.to(device), yb.to(device).float().unsqueeze(1)\n",
    "\n",
    "            start = time.time()\n",
    "            _, logits, _ = model(xb)\n",
    "            end = time.time()\n",
    "            batch_times.append(end - start)\n",
    "\n",
    "            loss = criterion(logits, yb)\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "            probs = pt.sigmoid(logits).cpu().numpy()\n",
    "            preds = (probs >= threshold).astype(int)\n",
    "\n",
    "            all_probs.extend(probs)\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "\n",
    "    avg_forward_time = sum(batch_times) / len(batch_times) if batch_times else 0.0\n",
    "    return total_loss / len(loader.dataset), acc, auc, f1, avg_forward_time\n",
    "\n",
    "\n",
    "def valid_at_epo_t(loader, model, criterion, device, step=0.01):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_labels, all_probs = [], []\n",
    "    batch_times = []\n",
    "\n",
    "    with pt.no_grad():\n",
    "        for xb, yb in tqdm(loader, desc=\"Test\", leave=False):\n",
    "            xb, yb = xb.to(device), yb.to(device).float().unsqueeze(1)\n",
    "\n",
    "            start = time.time()\n",
    "            _, logits, _ = model(xb)\n",
    "            end = time.time()\n",
    "            batch_times.append(end - start)\n",
    "\n",
    "            loss = criterion(logits, yb)\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "            probs = pt.sigmoid(logits).cpu().numpy()\n",
    "            all_probs.extend(probs)\n",
    "            all_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "    thresholds = [i * step for i in range(int(1 / step) + 1)]\n",
    "    best_s, best_f1, best_thr, best_acc = 0, 0, 0.5, 0\n",
    "\n",
    "    for thr in thresholds:\n",
    "        preds = (pt.tensor(all_probs) >= thr).int().numpy()\n",
    "        f1 = f1_score(all_labels, preds)\n",
    "        acc = accuracy_score(all_labels, preds)\n",
    "        if f1 * acc > best_s:\n",
    "            best_s, best_f1, best_thr, best_acc = f1 * acc, f1, thr, acc\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "\n",
    "    avg_forward_time = sum(batch_times) / len(batch_times) if batch_times else 0.0\n",
    "    return total_loss / len(loader.dataset), best_acc, auc, best_f1, best_thr, avg_forward_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T17:29:44.798787Z",
     "iopub.status.busy": "2025-11-14T17:29:44.798092Z",
     "iopub.status.idle": "2025-11-14T17:29:44.815078Z",
     "shell.execute_reply": "2025-11-14T17:29:44.814246Z",
     "shell.execute_reply.started": "2025-11-14T17:29:44.798766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "def make_log_mel_transform(sample_rate=16000,\n",
    "                           n_fft=400,        # 25 ms 16k\n",
    "                           hop_length=160,   # 10 ms 16k\n",
    "                           n_mels=40):\n",
    "    mel = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        win_length=n_fft,\n",
    "        window_fn=torch.hann_window,\n",
    "        n_mels=n_mels,\n",
    "        center=True,\n",
    "        power=2.0,\n",
    "    )\n",
    "    def transform(waveform):\n",
    "        \n",
    "        if waveform.dim() == 1:\n",
    "            waveform = waveform.unsqueeze(0)\n",
    "        mel_spec = mel(waveform) + 1e-4            # [1, n_mels, T]\n",
    "        log_mel = torchaudio.functional.amplitude_to_DB(\n",
    "            mel_spec, multiplier=10, amin=1e-4,\n",
    "            db_multiplier=torch.log10(torch.tensor(1e-4))\n",
    "        )           # [1, n_mels, T]\n",
    "        # normalize per-sample\n",
    "        m = log_mel.mean()\n",
    "        s = log_mel.std(unbiased=False)\n",
    "        log_mel = (log_mel - m) / (s + 1e-9)\n",
    "        return log_mel\n",
    "\n",
    "    return transform\n",
    "\n",
    "\n",
    "\n",
    "class SpeakerClassificationFeatureDataset(Dataset):\n",
    "    def __init__(self, file_list, fixed_len=40000, one_hot=False,\n",
    "                 augment=False, sample_rate=16000, n_mels=40):\n",
    "\n",
    "        self.fixed_len = fixed_len\n",
    "        self.one_hot = one_hot\n",
    "        self.augment = augment\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_mels = n_mels\n",
    "\n",
    "        self.files = [f for f, _ in file_list]\n",
    "        self.labels = [lbl for _, lbl in file_list]\n",
    "        self.num_speakers = len(set(self.labels))\n",
    "\n",
    "        # transform log-mel\n",
    "        self.logmel_fn = make_log_mel_transform(\n",
    "            sample_rate=sample_rate,\n",
    "            n_fft=400,\n",
    "            hop_length=160,\n",
    "            n_mels=n_mels\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "    \n",
    "    def augment_wave(self, wav):\n",
    "        sr = self.sample_rate\n",
    "\n",
    "        # noise\n",
    "        noise_level = random.uniform(0.00, 0.015)\n",
    "        wav = wav + torch.randn_like(wav) * noise_level\n",
    "\n",
    "        # gain\n",
    "        gain = random.uniform(0.5, 1.25)\n",
    "        wav = wav * gain\n",
    "        \n",
    "        # time-stretch & pitch\n",
    "        speed = random.uniform(0.85, 1.75)\n",
    "        pitch = random.uniform(-3, 3)  # semitones\n",
    "        reverb_wet = random.uniform(0.01, 0.6) * 100\n",
    "        room_size = random.uniform(0, 100)\n",
    "\n",
    "        effects = [\n",
    "            ['tempo', str(speed)],\n",
    "            ['pitch', str(pitch * 100)],  # Sox expects cents\n",
    "            ['reverb', str(reverb_wet), str(reverb_wet), str(room_size)]\n",
    "        ]\n",
    "        wav, _ = torchaudio.sox_effects.apply_effects_tensor(wav.unsqueeze(0), sr, effects)\n",
    "        wav = wav.mean(dim=0)\n",
    "\n",
    "        return wav\n",
    "\n",
    "\n",
    "    \n",
    "    def augment_spec(self, spec):\n",
    "        # spec: [1, n_mels, T]\n",
    "        freq_mask_param = random.randint(2, 12)\n",
    "        time_mask_param = random.randint(4, 28)\n",
    "        freq_mask = torchaudio.transforms.FrequencyMasking(freq_mask_param=freq_mask_param)\n",
    "        time_mask = torchaudio.transforms.TimeMasking(time_mask_param=time_mask_param)\n",
    "        spec = freq_mask(spec)\n",
    "        spec = time_mask(spec)\n",
    "        return spec\n",
    "\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.files[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        info = torchaudio.info(path)\n",
    "        total_len = info.num_frames\n",
    "\n",
    "        if total_len > self.fixed_len:\n",
    "            start = random.randint(0, total_len - self.fixed_len)\n",
    "            wav, sr = torchaudio.load(path, frame_offset=start, num_frames=self.fixed_len)\n",
    "        else:\n",
    "            wav, sr = torchaudio.load(path)\n",
    "        \n",
    "        wav = wav.mean(dim=0)\n",
    "        if sr != self.sample_rate:\n",
    "            wav = torchaudio.transforms.Resample(sr, self.sample_rate)(wav.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "        # aug\n",
    "        if self.augment:\n",
    "            wav = self.augment_wave(wav)\n",
    "\n",
    "        # pad\n",
    "        cur_len = wav.size(0)\n",
    "        if cur_len < self.fixed_len:\n",
    "            pad_total = self.fixed_len - cur_len\n",
    "            pad_left = random.randint(0, pad_total)\n",
    "            pad_right = pad_total - pad_left\n",
    "            wav = F.pad(wav, (pad_left, pad_right))\n",
    "        else:\n",
    "            start = random.randint(0, cur_len - self.fixed_len)\n",
    "            wav = wav[start:start+self.fixed_len]\n",
    "        \n",
    "        log_mel = self.logmel_fn(wav)  # [1, n_mels, T]\n",
    "        # aug spec\n",
    "        if self.augment:\n",
    "            log_mel = self.augment_spec(log_mel)\n",
    "\n",
    "        if self.one_hot:\n",
    "            lbl = torch.zeros(self.num_speakers)\n",
    "            lbl[label] = 1.0\n",
    "        else:\n",
    "            lbl = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return log_mel, lbl\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn_classification(batch):\n",
    "    feats = torch.stack([b[0] for b in batch], dim=0)\n",
    "    labels = torch.tensor([b[1] for b in batch], dtype=torch.long)\n",
    "    return feats, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "batch_s = 256\n",
    "\n",
    "tra_ds = SpeakerClassificationFeatureDataset(data_train, fixed_len=40000, one_hot=False, augment=True)\n",
    "tra_dl = DataLoader(tra_ds, batch_size=batch_s, shuffle=True, collate_fn=collate_fn_classification)\n",
    "val_ds = SpeakerClassificationFeatureDataset(data_valid, fixed_len=40000, one_hot=False, augment=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_s, shuffle=False, collate_fn=collate_fn_classification)\n",
    "tes_ds = SpeakerClassificationFeatureDataset(data_test, fixed_len=40000, one_hot=False, augment=False)\n",
    "tes_dl = DataLoader(tes_ds, batch_size=batch_s, shuffle=False, collate_fn=collate_fn_classification)\n",
    "\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T18:00:27.099557Z",
     "iopub.status.busy": "2025-11-14T18:00:27.099229Z",
     "iopub.status.idle": "2025-11-14T18:00:27.117986Z",
     "shell.execute_reply": "2025-11-14T18:00:27.117215Z",
     "shell.execute_reply.started": "2025-11-14T18:00:27.099535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = ConformerWithGates(num_classes=1, emb_dim=200, num_blocks=3, ff_expansion=4, hidden_dim=40).to(device)\n",
    "optimizer = pt.optim.Adam(model.parameters(), lr=4e-4)\n",
    "criterion = pt.nn.BCEWithLogitsLoss()\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T18:00:28.844195Z",
     "iopub.status.busy": "2025-11-14T18:00:28.843522Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, 25):\n",
    "\n",
    "    print(epoch)\n",
    "\n",
    "    train_loss, train_acc = train_one_epo(tra_dl, model, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc, valid_auc, valid_f1, valid_time = valid_at_epo(val_dl, model, criterion, device, 0.5)\n",
    "\n",
    "    print(f\"  Train -> loss: {train_loss:.4f}, acc: {train_acc:.4f}\")\n",
    "    print(f\"  Valid -> loss: {valid_loss:.4f}, acc: {valid_acc:.4f}, auc: {valid_auc:.4f}, f1: {valid_f1:.4f}, time: {valid_time:.4f}s\")\n",
    "\n",
    "    optimizer_info = {\n",
    "        'param_groups': [\n",
    "            {k: v for k, v in group.items() if k in ['lr', 'betas', 'weight_decay']}\n",
    "            for group in optimizer.param_groups\n",
    "        ]\n",
    "    }\n",
    "    ckpt_path = f\"igc_xs_{epoch}.pt\"\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"criterion_state\": criterion.state_dict(),\n",
    "        \"optimizer_info\": optimizer_info\n",
    "    }, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "_, test_acc, test_auc, test_f1, _ = valid_at_epo(tes_dl, model, criterion, device, 0.5)\n",
    "_, test_b_acc, test_b_auc, test_b_f1, test_b_thr, _ = valid_at_epo_t(tes_dl, model, criterion, device)\n",
    "print(f\"  Test -> acc: {test_acc:.4f}, auc: {test_auc:.4f}, f1: {test_f1:.4f}\")\n",
    "print(f\"  Test best  -> acc: {test_b_acc:.4f}, auc: {test_b_auc:.4f}, f1: {test_b_f1:.4f}, th: {test_b_thr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8250661,
     "sourceId": 13040120,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8511916,
     "sourceId": 13411965,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
